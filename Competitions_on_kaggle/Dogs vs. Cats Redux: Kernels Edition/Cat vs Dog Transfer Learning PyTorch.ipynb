{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1. Data preparation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # data visualization\n%matplotlib inline\nfrom tqdm import tqdm # visualization progress bar\nfrom zipfile import ZipFile # extract zip file\n\n# Input data files are available in the \"../input/\" directory.\nimport os\nprint(os.listdir(\"../input\"))\nimport shutil\nimport torch\nimport torchvision\nfrom torchvision import transforms, models\n\nfrom PIL import Image\nfrom random import sample","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# let's look at the contents of the archive\ntrain_data = ZipFile('../input/dogs-vs-cats-redux-kernels-edition/train.zip', 'r')\ntest_data = ZipFile('../input/dogs-vs-cats-redux-kernels-edition/test.zip', 'r')\n\n# extract the contents\ntrain_data.extractall()\ntest_data.extractall()\n\n# let's look at the working directory\nos.getcwd()\n\n# contents of our directory\ndata_root = '../working'\nprint(os.listdir(data_root))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define constant variable\nTRAIN_DIR = 'train_dir'\nVAL_DIR = 'val_dir'\nTEST_DIR = 'test_dir'\n\nbatch_size = 32\n\n# Name of classes\nlabels = ['dog', 'cat']\n\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy test files to the unknown folder\nshutil.copytree('../working/test', os.path.join(TEST_DIR, 'unknown'))\n\n# Create train and validation folders\nfor dir_name in [TRAIN_DIR, VAL_DIR]:\n    for label in labels:\n        os.makedirs(os.path.join(dir_name, label), exist_ok=True)\n\n# Every fifth images transfer to validation folder\nfor i, file_name in enumerate(tqdm(os.listdir('../working/train'))):\n    dest_dir = TRAIN_DIR if i % 5 != 0 else VAL_DIR\n\n    for label in labels:\n        if file_name.startswith(label):\n            shutil.copy(os.path.join('../working/train', file_name),\n                        os.path.join(dest_dir, label, file_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization part of train dataset\nn_samples = 20\nfor label in labels:\n    print('Class label: ' + label)\n    # path to train dataset for label\n    PATH = os.path.join('/kaggle/working/train_dir', label)\n    # shose random 20 images in test dir\n    sub_samples = sample(os.listdir(PATH,), n_samples)\n    plt.figure(figsize=(16, 12))\n    for i, image in enumerate(sub_samples):\n        plt.subplot(n_samples/5, 5, i+1)\n        img = Image.open(os.path.join(PATH, image))\n        plt.imshow(img)\n        plt.title(label)\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualisation part of test dataset\nn_samples = 20\n# shose random 20 images in test dir\nsub_samples = sample(os.listdir(os.path.join('../working/test'),), n_samples)\nplt.figure(figsize=(16, 12))\nprint('Test set')\nfor i, image in enumerate(sub_samples):\n    plt.subplot(n_samples/5, 5, i+1)\n    img = Image.open(os.path.join(os.path.join('../working/test'), image))\n    plt.imshow(img)\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform images\ntt_0 = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\n# tt_1 = transforms.Compose([\n#     transforms.CenterCrop(224),\n#     transforms.RandomHorizontalFlip(),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=mean, std=std)\n# ])\n\n# tt_2 = transforms.Compose([\n#     transforms.CenterCrop(224),\n#     transforms.RandomRotation(degrees=45),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=mean, std=std)\n# ])\n\n# tt_3 = transforms.Compose([\n#     transforms.CenterCrop(224),\n#     transforms.RandomAffine(10, translate=[0.5, 0.3], scale=[0.7, 1.3], shear=[-10, 10]),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=mean, std=std)\n# ])\n\n# tt_4 = transforms.Compose([\n#     transforms.RandomApply([\n#         transforms.ColorJitter(\n#             brightness=0.5,\n#             contrast=0.5,\n#             saturation=0.5,\n#             hue=0.5\n#         )\n#     ]),\n#     transforms.CenterCrop(224),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=mean, std=std)\n# ])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ntrain_dataset_0 = torchvision.datasets.ImageFolder(TRAIN_DIR, tt_0)\n# train_dataset_1 = torchvision.datasets.ImageFolder(TRAIN_DIR, tt_1)\n# train_dataset_2 = torchvision.datasets.ImageFolder(TRAIN_DIR, tt_2)\n# train_dataset_3 = torchvision.datasets.ImageFolder(TRAIN_DIR, tt_3)\n# train_dataset_4 = torchvision.datasets.ImageFolder(TRAIN_DIR, tt_4)\n\nval_dataset = torchvision.datasets.ImageFolder(VAL_DIR, val_transforms)\n\ntrain_dataset = torch.utils.data.ConcatDataset([train_dataset_0])\n#                                                 train_dataset_1,\n#                                                 train_dataset_2,\n#                                                 train_dataset_3,\n#                                                 train_dataset_4])\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)\n\nprint(len(train_dataloader), len(train_dataset))\nprint(len(val_dataloader), len(val_dataset))\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create function to vizualization train batch\ndef show_batch(X_batch, y_batch, batch_size):\n    plt.figure(figsize=(16, 10))\n    for i, (image_tensor, class_index) in enumerate(zip(X_batch, y_batch)):\n        image = image_tensor.permute(1, 2, 0).numpy()\n        image = std * image + mean\n        plt.subplot(batch_size/8, 8, i+1)\n        plt.imshow(image)\n        plt.title(labels[class_index])\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()\n\nfor i in range(1):\n    print('Batch', i+1)\n    X_batch, y_batch = next(iter(train_dataloader))\n    show_batch(X_batch, y_batch, batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Create neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Download pretrained model\nmodel = models.resnet152(pretrained=True)\n\n# Disable grad for all conv layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Add fully connected layer\nmodel.fc = torch.nn.Linear(model.fc.in_features, 2)\n\n# Translate model to GPU\nmodel = model.to(device)\n\n# Select loss function\nloss = torch.nn.CrossEntropyLoss()\n\n# Select optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n\n# Decay LR by a factor of 0.1 every 5 epochs\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, loss, optimizer, scheduler, num_epochs):\n    # write train history for visualization\n    train_accuracy_history = []\n    train_loss_history = []\n    val_accuracy_history = []\n    val_loss_history = []\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}:', flush=True)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                dataloader = val_dataloader\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.\n            running_acc = 0.\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                # forward and backward\n                with torch.set_grad_enabled(phase=='train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n\n            # compute mean loss and mean accuracy\n            epoch_loss = running_loss / len(dataloader)\n            epoch_acc = running_acc / len(dataloader)\n            \n            # write data for visualization\n            if phase == 'train':\n                train_accuracy_history.append(epoch_acc)\n                train_loss_history.append(epoch_loss)\n            else:\n                val_accuracy_history.append(epoch_acc)\n                val_loss_history.append(epoch_loss)\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}', flush=True)\n\n    return train_accuracy_history, train_loss_history, val_accuracy_history, val_loss_history, model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory_and_trained_model = train_model(model, loss, optimizer, scheduler, num_epochs=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Visualization training process"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = history_and_trained_model[:4]\ntrained_model = history_and_trained_model[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Drow graph for Accuracy and Loss on train and val subset\n# titles = ['Accuracy', 'Loss']\n# plt.figure(figsize=(16, 8))\n# for i in range(1, 3):\n#     plt.subplot(1, 2, i)\n#     plt.plot(history[0+i], label='Train', c='b')\n#     plt.plot(history[1+i], label='Val', c='orange')\n#     plt.title(titles[i-1])\n#     plt.grid()\n#     plt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_model.eval()\n\nfor inputs, labels_ in val_dataloader:\n    val_predictions = []\n    val_img_paths = []\n    inputs = inputs.to(device)\n    labels_ = labels_.to(device)\n    with torch.set_grad_enabled(False):\n        preds = trained_model(inputs)\n    val_predictions.append(torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu())\n    labels_ = labels_.cpu().numpy()\n    predict = val_predictions[0] > 0.5\n    val_predictions = val_predictions[0].numpy()\n    predict = predict.numpy()\n    ind = (labels_ == predict)\n    \n    image_tensors = []\n    true_labels = []\n    predicted_labels = []\n    val_preds = []\n    for i, image_tensor in enumerate(inputs):\n        if ind[i] == False:\n            image_tensors.append(image_tensor)\n            true_labels.append(labels[predict[i]])\n            predicted_labels.append(labels[labels_[i]])\n            val_preds.append(val_predictions[i])\n    \n    plt.figure(figsize=(16, 16))    \n    for i, image_tensor in enumerate(image_tensors):\n        plt.subplot(len(image_tensors), 5, i+1)\n        image = image_tensor.cpu().permute(1, 2, 0).numpy()\n        image = std * image + mean\n        plt.imshow(image)\n        plt.title(f'True label: {true_labels[i]}\\n predicted label: {predicted_labels[i]} - {val_preds[i]:.4f}')\n        plt.xticks([])\n        plt.yticks([])\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Prediction for test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modify the folder with images so that it displays not only the image with its label,\n# but also the path to the image\nclass ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n\ntest_dataset = ImageFolderWithPaths(TEST_DIR, val_transforms)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy test files to the unknown folder\nos.makedirs(os.path.join('../working/', 'for-test'), exist_ok=True)\nshutil.copytree('../input/fortest/', '../working/for-test/for-test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cat_dataset = ImageFolderWithPaths('../working/for-test', val_transforms)\n\ntest_cat_dataloader = torch.utils.data.DataLoader(\n    test_cat_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn model to evel mode, parametrs do not changed\ntrained_model.eval()\n\n# predictions\ntest_predictions = []\n\n# paths to images\ntest_img_paths = []\n\n# In loop receive Batch with images, class label 'unknown' and image paths \nfor inputs, labels, paths in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        # count preds of model\n        preds = model(inputs)\n    # with SoftMax make probabilities\n    # get the probability of the first class ('dirty plate')\n    test_predictions.append(torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    # paths needs for visualization and save preds\n    test_img_paths.extend(paths)\n\ntest_predictions = np.concatenate(test_predictions)\nprediction = dict(zip(test_img_paths, test_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn model to evel mode, parametrs do not changed\ntrained_model.eval()\n\n# predictions\ntest_predictions = []\n\n# paths to images\ntest_img_paths = []\n\n# In loop receive Batch with images, class label 'unknown' and image paths \nfor inputs, labels, paths in tqdm(test_cat_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        # count preds of model\n        preds = model(inputs)\n    # with SoftMax make probabilities\n    # get the probability of the first class ('dirty plate')\n    test_predictions.append(torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    # paths needs for visualization and save preds\n    test_img_paths.extend(paths)\n\ntest_predictions = np.concatenate(test_predictions)\nprediction = dict(zip(test_img_paths, test_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization predictions of classifire\nplt.figure(figsize=(16, 12))\nprint('Visualization predictions for test set')\nfor i, image in enumerate(test_img_paths):\n    plt.subplot(1, 2, i+1)\n    img = Image.open(image)\n    plt.imshow(img)\n    title = 'dog' if prediction[image] > 0.5 else 'cat'\n    title = f'This is a {title}: {1 - prediction[image]:.4f}'\n    plt.title(title)\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization predictions of classifire\nn_samples = 25\nsub_sample = sample(test_img_paths, n_samples)\nplt.figure(figsize=(16, 12))\nprint('Visualization predictions for test set')\nfor i, image in enumerate(sub_sample):\n    plt.subplot(n_samples/5, 5, i+1)\n    img = Image.open(image)\n    plt.imshow(img)\n    title = 'dog' if prediction[image] > 0.5 else 'cat'\n    title = f'This is a {title}: {prediction[image]:.4f}'\n    plt.title(title)\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Create  submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create DataFrame from paths to images and class labels\nsubmission_df = pd.DataFrame.from_dict({'id': test_img_paths, \n                                        'label': test_predictions})\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clear id, leaving only image number and transform probabilities to classes\nsubmission_df['label'] = submission_df['label'].map(lambda pred: 1 if pred > 0.5 else 0)\nsubmission_df['id'] = submission_df['id'].str.replace('test_dir/unknown/', '')\nsubmission_df['id'] = submission_df['id'].str.replace('.jpg', '')\nsubmission_df['id'] = submission_df['id'].astype(int)\nsubmission_df = submission_df.sort_values(by='id')\nsubmission_df = submission_df.reset_index()\nsubmission_df = submission_df.drop(['index'], axis='columns')\nsubmission_df = submission_df.drop(['id'], axis='columns')\nsubmission_df.index.name = 'id'\nsubmission_df.index += 1\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Deleting all temprary files"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf train val test train_dir test_dir val_dir","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}